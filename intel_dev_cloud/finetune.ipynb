{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers>=4.38.* in /home/sdp/.local/lib/python3.10/site-packages (4.40.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.38.*) (4.66.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.38.*) (0.4.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers>=4.38.*) (5.4.1)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers>=4.38.*) (2.25.1)\n",
            "Requirement already satisfied: filelock in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.38.*) (3.13.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.38.*) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.38.*) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.38.*) (2024.4.16)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.38.*) (24.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.38.*) (0.22.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sdp/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.38.*) (4.11.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/sdp/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.38.*) (2023.10.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: datasets>=2.18.* in /home/sdp/.local/lib/python3.10/site-packages (2.19.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (0.22.2)\n",
            "Requirement already satisfied: xxhash in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (3.4.1)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (2023.10.0)\n",
            "Requirement already satisfied: filelock in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (16.0.0)\n",
            "Requirement already satisfied: aiohttp in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (3.9.5)\n",
            "Requirement already satisfied: packaging in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets>=2.18.*) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (1.26.4)\n",
            "Requirement already satisfied: pandas in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (1.3.5)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (0.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from datasets>=2.18.*) (2.25.1)\n",
            "Requirement already satisfied: multiprocess in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (0.70.15)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (0.3.7)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /home/sdp/.local/lib/python3.10/site-packages (from datasets>=2.18.*) (4.66.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.*) (1.9.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.*) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.*) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.*) (6.0.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets>=2.18.*) (21.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.18.*) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sdp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets>=2.18.*) (4.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /home/sdp/.local/lib/python3.10/site-packages (from pandas->datasets>=2.18.*) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->datasets>=2.18.*) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas->datasets>=2.18.*) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets>=2.18.*) (3.3)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: wandb>=0.16.* in /home/sdp/.local/lib/python3.10/site-packages (0.17.0rc2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /home/sdp/.local/lib/python3.10/site-packages (from wandb>=0.16.*) (5.9.8)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb>=0.16.*) (59.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from wandb>=0.16.*) (5.4.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/sdp/.local/lib/python3.10/site-packages (from wandb>=0.16.*) (3.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/lib/python3/dist-packages (from wandb>=0.16.*) (2.25.1)\n",
            "Requirement already satisfied: setproctitle in /home/sdp/.local/lib/python3.10/site-packages (from wandb>=0.16.*) (1.3.3)\n",
            "Requirement already satisfied: platformdirs in /home/sdp/.local/lib/python3.10/site-packages (from wandb>=0.16.*) (4.2.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/sdp/.local/lib/python3.10/site-packages (from wandb>=0.16.*) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/sdp/.local/lib/python3.10/site-packages (from wandb>=0.16.*) (3.1.43)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/lib/python3/dist-packages (from wandb>=0.16.*) (8.0.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/sdp/.local/lib/python3.10/site-packages (from wandb>=0.16.*) (2.0.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.16.*) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/sdp/.local/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.16.*) (4.0.11)\n",
            "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=1.0.0->wandb>=0.16.*) (2020.6.20)\n",
            "Requirement already satisfied: urllib3>=1.26.11 in /home/sdp/.local/lib/python3.10/site-packages (from sentry-sdk>=1.0.0->wandb>=0.16.*) (2.2.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/sdp/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.16.*) (5.0.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: trl>=0.7.11 in /home/sdp/.local/lib/python3.10/site-packages (0.8.6)\n",
            "Requirement already satisfied: accelerate in /home/sdp/.local/lib/python3.10/site-packages (from trl>=0.7.11) (0.29.3)\n",
            "Requirement already satisfied: datasets in /home/sdp/.local/lib/python3.10/site-packages (from trl>=0.7.11) (2.19.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /home/sdp/.local/lib/python3.10/site-packages (from trl>=0.7.11) (0.8.3)\n",
            "Requirement already satisfied: torch>=1.4.0 in /home/sdp/.local/lib/python3.10/site-packages (from trl>=0.7.11) (2.2.2)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /home/sdp/.local/lib/python3.10/site-packages (from trl>=0.7.11) (4.40.1)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /home/sdp/.local/lib/python3.10/site-packages (from trl>=0.7.11) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (4.11.0)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (8.9.2.26)\n",
            "Requirement already satisfied: fsspec in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (2023.10.0)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (2.2.0)\n",
            "Requirement already satisfied: filelock in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (3.13.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (12.1.105)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.4.0->trl>=0.7.11) (3.0.3)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (2.19.3)\n",
            "Requirement already satisfied: sympy in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (1.12)\n",
            "Requirement already satisfied: networkx in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.4.0->trl>=0.7.11) (3.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/sdp/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl>=0.7.11) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.11) (2024.4.16)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers>=4.31.0->trl>=0.7.11) (2.25.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.11) (0.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.11) (24.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.11) (4.66.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.11) (0.19.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers>=4.31.0->trl>=0.7.11) (5.4.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/sdp/.local/lib/python3.10/site-packages (from transformers>=4.31.0->trl>=0.7.11) (0.22.2)\n",
            "Requirement already satisfied: rich>=11.1.0 in /home/sdp/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.7.11) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /home/sdp/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.7.11) (1.7.1)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /home/sdp/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.7.11) (0.16)\n",
            "Requirement already satisfied: psutil in /home/sdp/.local/lib/python3.10/site-packages (from accelerate->trl>=0.7.11) (5.9.8)\n",
            "Requirement already satisfied: aiohttp in /home/sdp/.local/lib/python3.10/site-packages (from datasets->trl>=0.7.11) (3.9.5)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/sdp/.local/lib/python3.10/site-packages (from datasets->trl>=0.7.11) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /home/sdp/.local/lib/python3.10/site-packages (from datasets->trl>=0.7.11) (3.4.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /home/sdp/.local/lib/python3.10/site-packages (from datasets->trl>=0.7.11) (16.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/sdp/.local/lib/python3.10/site-packages (from datasets->trl>=0.7.11) (0.6)\n",
            "Requirement already satisfied: multiprocess in /home/sdp/.local/lib/python3.10/site-packages (from datasets->trl>=0.7.11) (0.70.15)\n",
            "Requirement already satisfied: pandas in /home/sdp/.local/lib/python3.10/site-packages (from datasets->trl>=0.7.11) (1.3.5)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.11) (1.4.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.11) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.11) (1.9.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.11) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets->trl>=0.7.11) (21.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sdp/.local/lib/python3.10/site-packages (from aiohttp->datasets->trl>=0.7.11) (6.0.5)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/sdp/.local/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.11) (2.17.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/sdp/.local/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.11) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /home/sdp/.local/lib/python3.10/site-packages (from pandas->datasets->trl>=0.7.11) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->datasets->trl>=0.7.11) (2022.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/sdp/.local/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl>=0.7.11) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/sdp/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl>=0.7.11) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas->datasets->trl>=0.7.11) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets->trl>=0.7.11) (3.3)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: peft>=0.9.0 in /home/sdp/.local/lib/python3.10/site-packages (0.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from peft>=0.9.0) (5.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/sdp/.local/lib/python3.10/site-packages (from peft>=0.9.0) (24.0)\n",
            "Requirement already satisfied: transformers in /home/sdp/.local/lib/python3.10/site-packages (from peft>=0.9.0) (4.40.1)\n",
            "Requirement already satisfied: tqdm in /home/sdp/.local/lib/python3.10/site-packages (from peft>=0.9.0) (4.66.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/sdp/.local/lib/python3.10/site-packages (from peft>=0.9.0) (0.22.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /home/sdp/.local/lib/python3.10/site-packages (from peft>=0.9.0) (2.2.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /home/sdp/.local/lib/python3.10/site-packages (from peft>=0.9.0) (0.29.3)\n",
            "Requirement already satisfied: psutil in /home/sdp/.local/lib/python3.10/site-packages (from peft>=0.9.0) (5.9.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/sdp/.local/lib/python3.10/site-packages (from peft>=0.9.0) (1.26.4)\n",
            "Requirement already satisfied: safetensors in /home/sdp/.local/lib/python3.10/site-packages (from peft>=0.9.0) (0.4.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/sdp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft>=0.9.0) (2023.10.0)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub>=0.17.0->peft>=0.9.0) (2.25.1)\n",
            "Requirement already satisfied: filelock in /home/sdp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft>=0.9.0) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sdp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft>=0.9.0) (4.11.0)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (12.1.105)\n",
            "Requirement already satisfied: sympy in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (1.12)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (11.4.5.107)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.13.0->peft>=0.9.0) (3.0.3)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (12.1.3.1)\n",
            "Requirement already satisfied: networkx in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft>=0.9.0) (3.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/sdp/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft>=0.9.0) (12.4.127)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/sdp/.local/lib/python3.10/site-packages (from transformers->peft>=0.9.0) (0.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/sdp/.local/lib/python3.10/site-packages (from transformers->peft>=0.9.0) (2024.4.16)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/sdp/.local/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft>=0.9.0) (1.3.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: accelerate>=0.28.* in /home/sdp/.local/lib/python3.10/site-packages (0.29.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/sdp/.local/lib/python3.10/site-packages (from accelerate>=0.28.*) (0.4.3)\n",
            "Requirement already satisfied: psutil in /home/sdp/.local/lib/python3.10/site-packages (from accelerate>=0.28.*) (5.9.8)\n",
            "Requirement already satisfied: torch>=1.10.0 in /home/sdp/.local/lib/python3.10/site-packages (from accelerate>=0.28.*) (2.2.2)\n",
            "Requirement already satisfied: huggingface-hub in /home/sdp/.local/lib/python3.10/site-packages (from accelerate>=0.28.*) (0.22.2)\n",
            "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate>=0.28.*) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/sdp/.local/lib/python3.10/site-packages (from accelerate>=0.28.*) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/sdp/.local/lib/python3.10/site-packages (from accelerate>=0.28.*) (24.0)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (2.19.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (4.11.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (8.9.2.26)\n",
            "Requirement already satisfied: sympy in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (1.12)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (12.1.105)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.10.0->accelerate>=0.28.*) (3.0.3)\n",
            "Requirement already satisfied: filelock in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (3.13.4)\n",
            "Requirement already satisfied: fsspec in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (11.0.2.54)\n",
            "Requirement already satisfied: networkx in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (3.3)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/sdp/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.28.*) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/sdp/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.28.*) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub->accelerate>=0.28.*) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/sdp/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.28.*) (4.66.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/sdp/.local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.28.*) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import site\n",
        "import os\n",
        "\n",
        "# Install the required packages\n",
        "!{sys.executable} -m pip install --upgrade  \"transformers>=4.38.*\"\n",
        "!{sys.executable} -m pip install --upgrade  \"datasets>=2.18.*\"\n",
        "!{sys.executable} -m pip install --upgrade \"wandb>=0.16.*\"\n",
        "!{sys.executable} -m pip install --upgrade \"trl>=0.7.11\"\n",
        "!{sys.executable} -m pip install --upgrade \"peft>=0.9.0\"\n",
        "!{sys.executable} -m pip install --upgrade \"accelerate>=0.28.*\"\n",
        "\n",
        "# Get the site-packages directory\n",
        "site_packages_dir = site.getsitepackages()[0]\n",
        "\n",
        "# add the site pkg directory where these pkgs are insalled to the top of sys.path\n",
        "if not os.access(site_packages_dir, os.W_OK):\n",
        "    user_site_packages_dir = site.getusersitepackages()\n",
        "    if user_site_packages_dir in sys.path:\n",
        "        sys.path.remove(user_site_packages_dir)\n",
        "    sys.path.insert(0, user_site_packages_dir)\n",
        "else:\n",
        "    if site_packages_dir in sys.path:\n",
        "        sys.path.remove(site_packages_dir)\n",
        "    sys.path.insert(0, site_packages_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of physical cores: 112\n",
            "Number of cores per socket: 56\n",
            "OpenMP environment variables:\n",
            "  - OMP_NUM_THREADS: 112\n",
            "  - OMP_PROC_BIND: close\n",
            "  - OMP_PLACES: cores\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import psutil\n",
        "\n",
        "num_physical_cores = psutil.cpu_count(logical=False)\n",
        "num_cores_per_socket = num_physical_cores // 2\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"0\"\n",
        "#HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
        "\n",
        "# Set the LD_PRELOAD environment variable\n",
        "ld_preload = os.environ.get(\"LD_PRELOAD\", \"\")\n",
        "conda_prefix = os.environ.get(\"CONDA_PREFIX\", \"\")\n",
        "# Improve memory allocation performance, if tcmalloc is not available, please comment this line out\n",
        "os.environ[\"LD_PRELOAD\"] = f\"{ld_preload}:{conda_prefix}/lib/libtcmalloc.so\"\n",
        "# Reduce the overhead of submitting commands to the GPU\n",
        "os.environ[\"SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS\"] = \"1\"\n",
        "# reducing memory accesses by fusing SDP ops\n",
        "os.environ[\"ENABLE_SDP_FUSION\"] = \"1\"\n",
        "# set openMP threads to number of physical cores\n",
        "os.environ[\"OMP_NUM_THREADS\"] = str(num_physical_cores)\n",
        "# Set the thread affinity policy\n",
        "os.environ[\"OMP_PROC_BIND\"] = \"close\"\n",
        "# Set the places for thread pinning\n",
        "os.environ[\"OMP_PLACES\"] = \"cores\"\n",
        "\n",
        "print(f\"Number of physical cores: {num_physical_cores}\")\n",
        "print(f\"Number of cores per socket: {num_cores_per_socket}\")\n",
        "print(f\"OpenMP environment variables:\")\n",
        "print(f\"  - OMP_NUM_THREADS: {os.environ['OMP_NUM_THREADS']}\")\n",
        "print(f\"  - OMP_PROC_BIND: {os.environ['OMP_PROC_BIND']}\")\n",
        "print(f\"  - OMP_PLACES: {os.environ['OMP_PLACES']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XPU device not available.\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import threading\n",
        "import torch\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import torch\n",
        "import intel_extension_for_pytorch as ipex\n",
        "\n",
        "if torch.xpu.is_available():\n",
        "    torch.xpu.empty_cache()\n",
        "    \n",
        "    def get_memory_usage():\n",
        "        memory_reserved = round(torch.xpu.memory_reserved() / 1024**3, 3)\n",
        "        memory_allocated = round(torch.xpu.memory_allocated() / 1024**3, 3)\n",
        "        max_memory_reserved = round(torch.xpu.max_memory_reserved() / 1024**3, 3)\n",
        "        max_memory_allocated = round(torch.xpu.max_memory_allocated() / 1024**3, 3)\n",
        "        return memory_reserved, memory_allocated, max_memory_reserved, max_memory_allocated\n",
        "   \n",
        "    def print_memory_usage():\n",
        "        device_name = torch.xpu.get_device_name()\n",
        "        print(f\"XPU Name: {device_name}\")\n",
        "        memory_reserved, memory_allocated, max_memory_reserved, max_memory_allocated = get_memory_usage()\n",
        "        memory_usage_text = f\"XPU Memory: Reserved={memory_reserved} GB, Allocated={memory_allocated} GB, Max Reserved={max_memory_reserved} GB, Max Allocated={max_memory_allocated} GB\"\n",
        "        print(f\"\\r{memory_usage_text}\", end=\"\", flush=True)\n",
        "    \n",
        "    async def display_memory_usage(output):\n",
        "        device_name = torch.xpu.get_device_name()\n",
        "        output.update(HTML(f\"<p>XPU Name: {device_name}</p>\"))\n",
        "        while True:\n",
        "            memory_reserved, memory_allocated, max_memory_reserved, max_memory_allocated = get_memory_usage()\n",
        "            memory_usage_text = f\"XPU ({device_name}) :: Memory: Reserved={memory_reserved} GB, Allocated={memory_allocated} GB, Max Reserved={max_memory_reserved} GB, Max Allocated={max_memory_allocated} GB\"\n",
        "            output.update(HTML(f\"<p>{memory_usage_text}</p>\"))\n",
        "            await asyncio.sleep(5)\n",
        "    \n",
        "    def start_memory_monitor(output):\n",
        "        loop = asyncio.new_event_loop()\n",
        "        asyncio.set_event_loop(loop)\n",
        "        loop.create_task(display_memory_usage(output))\n",
        "        thread = threading.Thread(target=loop.run_forever)\n",
        "        thread.start()    \n",
        "    output = display(display_id=True)\n",
        "    start_memory_monitor(output)\n",
        "else:\n",
        "    print(\"XPU device not available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-28 10:43:33,271 - bitsandbytes.cextension - WARNING - The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    # could use q, v and 0 projections as well and comment out the rest\n",
        "    target_modules=[\"q_proj\", \"o_proj\", \n",
        "                    \"v_proj\", \"k_proj\", \n",
        "                    \"gate_proj\", \"up_proj\",\n",
        "                    \"down_proj\"],\n",
        "    task_type=\"CAUSAL_LM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
            "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "083968b5cfdd4c069e24646329a61a39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "USE_CPU = False\n",
        "device = \"xpu:0\" if torch.xpu.is_available() else \"cpu\"\n",
        "if USE_CPU:\n",
        "    device = \"cpu\"\n",
        "print(f\"using device: {device}\")\n",
        "\n",
        "model_id = \"google/gemma-2b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "# Set padding side to the right to ensure proper attention masking during fine-tuning\n",
        "tokenizer.padding_side = \"right\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
        "# Disable caching mechanism to reduce memory usage during fine-tuning\n",
        "model.config.use_cache = False\n",
        "# Configure the model's pre-training tensor parallelism degree to match the fine-tuning setup\n",
        "model.config.pretraining_tp = 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing the model before fine-tuning:\n",
            "__________________________________________________\n",
            "Write a story about a futuristic city where robots and humans coexist, focusing on the friendship between a young girl and her robot companion.\n",
            "Generated Answer: Write a story about a futuristic city where robots and humans coexist, focusing on the friendship between a young girl and her robot companion.\n",
            "\n",
            "Answer:\n",
            "\n",
            "Step 1/2\n",
            "Once upon a time, there was a young girl named Sarah who lived in a futuristic city. The city was filled with advanced technology and robots that were used for various purposes. Sarah was a curious girl who loved to explore and learn about the world around her. One day, Sarah was walking through the city when she saw a robot standing on a street corner. The robot was wearing a blue jumpsuit and had a friendly smile on its face. Sarah approached\n",
            "\n",
            "__________________________________________________\n",
            "__________________________________________________\n",
            "Craft a mystery story set in a Victorian-era mansion, involving a secret society and a missing heirloom.\n",
            "Generated Answer: Craft a mystery story set in a Victorian-era mansion, involving a secret society and a missing heirloom.\n",
            "\n",
            "The story begins with a young woman, who is the daughter of a wealthy family, who is sent to live with her aunt and uncle in a large mansion. The aunt and uncle are both members of a secret society, and the young woman is expected to join them. However, she is not interested in the society, and she is determined to find out what happened to her father, who disappeared many years ago.\n",
            "\n",
            "As the story unfolds, the young woman discovers that the mansion is haunted by\n",
            "\n",
            "__________________________________________________\n",
            "__________________________________________________\n",
            "Develop a thriller that takes place during a severe snowstorm in a remote mountain cabin, with characters who discover they are not alone.\n",
            "Generated Answer: Develop a thriller that takes place during a severe snowstorm in a remote mountain cabin, with characters who discover they are not alone.\n",
            "\n",
            "The story should be told from the point of view of a young woman who is trapped in the cabin with her boyfriend and his two friends.\n",
            "\n",
            "The story should be told in the first person, and should be told in a way that makes the reader feel like they are in the cabin with the characters.\n",
            "\n",
            "The story should be suspenseful and have a lot of twists and turns.\n",
            "\n",
            "The story should also have a lot of action, and should be told in a way that makes the reader\n",
            "\n",
            "__________________________________________________\n",
            "__________________________________________________\n",
            "Compose a fantasy tale about a kingdom threatened by a mythical creature, seen through the eyes of a young apprentice wizard tasked with saving the realm.\n",
            "Generated Answer: Compose a fantasy tale about a kingdom threatened by a mythical creature, seen through the eyes of a young apprentice wizard tasked with saving the realm.\n",
            "\n",
            "The story is told in the first person by a young apprentice wizard, who is tasked with saving the realm from a mythical creature. The apprentice wizard is a young apprentice wizard who is tasked with saving the realm from a mythical creature. The apprentice wizard is a young apprentice wizard who is tasked with saving the realm from a mythical creature. The apprentice wizard is a young apprentice wizard who is tasked with saving the realm from a mythical creature. The apprentice wizard is a young apprentice wizard who is tasked with saving\n",
            "\n",
            "__________________________________________________\n",
            "__________________________________________________\n",
            "Create a romantic story set on a Mediterranean cruise, where two strangers from different backgrounds fall in love while dealing with personal challenges.\n",
            "Generated Answer: Create a romantic story set on a Mediterranean cruise, where two strangers from different backgrounds fall in love while dealing with personal challenges.\n",
            "\n",
            "The story begins with a young woman named Anna, who is on a cruise with her husband, who is a successful businessman. Anna is a free-spirited woman who is not afraid to speak her mind and is not afraid to take risks. She is also a talented artist who loves to paint and draw.\n",
            "\n",
            "One night, Anna meets a young man named Alex, who is also on the cruise. Alex is a shy and introverted man who is struggling with his own personal challenges. He is\n",
            "\n",
            "__________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def generate_response(model, prompt):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)    \n",
        "    outputs = model.generate(input_ids, max_new_tokens=100,\n",
        "                             eos_token_id=tokenizer.eos_token_id)    \n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def test_model(model, test_inputs):\n",
        "    \"\"\"quickly test the model using queries.\"\"\"\n",
        "    for input_text in test_inputs:\n",
        "        print(\"__\"*25)\n",
        "        generated_response = generate_response(model, input_text)\n",
        "        print(f\"{input_text}\")\n",
        "        print(f\"Generated Answer: {generated_response}\\n\")\n",
        "        print(\"__\"*25)\n",
        "\n",
        "test_inputs = [\n",
        "\"Write a story about a futuristic city where robots and humans coexist, focusing on the friendship between a young girl and her robot companion.\",\n",
        "\"Craft a mystery story set in a Victorian-era mansion, involving a secret society and a missing heirloom.\",\n",
        "\"Develop a thriller that takes place during a severe snowstorm in a remote mountain cabin, with characters who discover they are not alone.\",\n",
        "\"Compose a fantasy tale about a kingdom threatened by a mythical creature, seen through the eyes of a young apprentice wizard tasked with saving the realm.\",\n",
        "\"Create a romantic story set on a Mediterranean cruise, where two strangers from different backgrounds fall in love while dealing with personal challenges.\"\n",
        "]\n",
        "\n",
        "print(\"Testing the model before fine-tuning:\")\n",
        "test_model(model, test_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-28 10:44:00,276 - datasets - INFO - PyTorch version 2.2.2 available.\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"PocketDoc/RUCAIBox-Story-Generation-Alpaca\"\n",
        "dataset = load_dataset(dataset_name ,split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instruction': 'Your story should involve \"My dog was diagnosed with congestive heart failure. He hung on for 9 months. We eventually had to put him to sleep.\" in a brief, concise manner.', 'input': '', 'output': 'It was such a sad time. We had to put him to sleep right before my daughters high school graduation. We had company coming in to town for graduation. After the dog passed away we were all so sad and did not have a lot of energy to get the house ready for company. The dog was my best friend. He was so sweet and kind and loving. He followed me everywhere. He loved to cuddle with me on the couch and put his head on the backs of my knees. It was such a soothing experience being cuddled up like that with him. When we discovered he was dying we found a puppy from a little girl on craigslist. She could not take care of the puppy and happily sold him to us. The puppy was great for the dying dog. It gave the dog a purpose and something to focus on, training the new guy. At first the puppy looked at us in shock, as if to say, \"Rules??? I don\\'t do rules!\" He quickly came around when he discovered there were treats to be earned by following the rules. I am glad we got a puppy as the older dog was dying. He made life a little more enjoyable after the old dog passed away. I still miss the old dog. I hope when I get to heaven that he comes running to greet me!'}\n",
            "Instruction is: Your story should involve \"My dog was diagnosed with congestive heart failure. He hung on for 9 months. We eventually had to put him to sleep.\" in a brief, concise manner.\n",
            "Response is: It was such a sad time. We had to put him to sleep right before my daughters high school graduation. We had company coming in to town for graduation. After the dog passed away we were all so sad and did not have a lot of energy to get the house ready for company. The dog was my best friend. He was so sweet and kind and loving. He followed me everywhere. He loved to cuddle with me on the couch and put his head on the backs of my knees. It was such a soothing experience being cuddled up like that with him. When we discovered he was dying we found a puppy from a little girl on craigslist. She could not take care of the puppy and happily sold him to us. The puppy was great for the dying dog. It gave the dog a purpose and something to focus on, training the new guy. At first the puppy looked at us in shock, as if to say, \"Rules??? I don't do rules!\" He quickly came around when he discovered there were treats to be earned by following the rules. I am glad we got a puppy as the older dog was dying. He made life a little more enjoyable after the old dog passed away. I still miss the old dog. I hope when I get to heaven that he comes running to greet me!\n",
            "Number of examples in the dataset: 6168\n",
            "Fields in the dataset: ['instruction', 'input', 'output']\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0])\n",
        "\n",
        "print(f\"Instruction is: {dataset[0]['instruction']}\")\n",
        "print(f\"Response is: {dataset[0]['output']}\")\n",
        "\n",
        "\n",
        "print(f\"Number of examples in the dataset: {len(dataset)}\")\n",
        "print(f\"Fields in the dataset: {list(dataset.features.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_prompts(batch):\n",
        "    formatted_prompts = []\n",
        "    for instruction, user_input, response in zip(batch[\"instruction\"], batch['input'], batch[\"output\"]):\n",
        "        prompt = f\"Instruction:\\n{instruction}\\n\\n{user_input}\\n\\nResponse:\\n{response}\"\n",
        "        formatted_prompts.append(prompt)\n",
        "    return {\"text\": formatted_prompts}\n",
        "\n",
        "dataset = dataset.map(format_prompts, batched=True)\n",
        "split_dataset = dataset.train_test_split(test_size=0.2, seed=99)\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "validation_dataset = split_dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finetuning for max number of steps: 154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "2024-04-28 10:44:10,876 - wandb.jupyter - ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "ERROR: ld.so: object '/lib/libtcmalloc.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbillzhangsc\u001b[0m (\u001b[33mbillzhang-25\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "ERROR: ld.so: object '/lib/libtcmalloc.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/lib/libtcmalloc.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0rc2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/sdp/llms/wandb/run-20240428_104411-gcp1v382</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/billzhang-25/gemma_storytelling/runs/gcp1v382' target=\"_blank\">winter-oath-3</a></strong> to <a href='https://wandb.ai/billzhang-25/gemma_storytelling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/billzhang-25/gemma_storytelling' target=\"_blank\">https://wandb.ai/billzhang-25/gemma_storytelling</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/billzhang-25/gemma_storytelling/runs/gcp1v382' target=\"_blank\">https://wandb.ai/billzhang-25/gemma_storytelling/runs/gcp1v382</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='154' max='154' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [154/154 6:31:55, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1454737970954.239990</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "ERROR: ld.so: object '/lib/libtcmalloc.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
            "ERROR: ld.so: object '/lib/libtcmalloc.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time:  23659.11\n",
            "Samples/second:  0.21\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'get_memory_usage' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m     torch\u001b[38;5;241m.\u001b[39mxpu\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     63\u001b[0m results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 64\u001b[0m \u001b[43mprint_training_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# save lora model\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mprint_training_summary\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_runtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSamples/second: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_samples_per_second\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mget_memory_usage\u001b[49m()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_memory_usage' is not defined"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "import wandb\n",
        "\n",
        "from trl import SFTTrainer\n",
        "\n",
        "os.environ[\"WANDB_PROJECT\"] = \"gemma_storytelling\"  \n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
        "os.environ[\"IPEX_TILE_AS_DEVICE\"] = \"1\"\n",
        "\n",
        "finetuned_model_id = \"Maelstrome/gemma-2b-storytelling\"\n",
        "PUSH_TO_HUB = True\n",
        "USE_WANDB = False\n",
        "\n",
        "# Calculate max_steps based on the subset size\n",
        "num_train_samples = len(train_dataset)\n",
        "batch_size = 4\n",
        "gradient_accumulation_steps = 8\n",
        "steps_per_epoch = num_train_samples // (batch_size * gradient_accumulation_steps)\n",
        "num_epochs = 1\n",
        "max_steps = steps_per_epoch * num_epochs\n",
        "print(f\"Finetuning for max number of steps: {max_steps}\")\n",
        "\n",
        "\n",
        "\n",
        "training_args = transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        warmup_ratio=0.05,\n",
        "        max_steps=max_steps,\n",
        "        learning_rate=1e-5,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        save_steps=500,\n",
        "        bf16=True,\n",
        "        logging_steps=100,\n",
        "        output_dir=finetuned_model_id,\n",
        "        hub_model_id=finetuned_model_id if PUSH_TO_HUB else None,\n",
        "        use_ipex=True,\n",
        "        report_to=\"wandb\" if USE_WANDB else None,\n",
        "        push_to_hub=PUSH_TO_HUB,\n",
        "        max_grad_norm=0.6,\n",
        "        weight_decay=0.01,\n",
        "        group_by_length=True\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    peft_config=lora_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        "    packing=True\n",
        ")\n",
        "\n",
        "if device != \"cpu\":\n",
        "    print_memory_usage()\n",
        "    torch.xpu.empty_cache()\n",
        "results = trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time:  23659.11\n",
            "Samples/second:  0.21\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65aa09db6177425b94dc186eb79c287c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='166.436 MB of 166.436 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁█</td></tr><tr><td>train/global_step</td><td>▁▁█</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>nan</td></tr><tr><td>eval/runtime</td><td>767.2118</td></tr><tr><td>eval/samples_per_second</td><td>1.125</td></tr><tr><td>eval/steps_per_second</td><td>0.141</td></tr><tr><td>total_flos</td><td>3.05785512394752e+16</td></tr><tr><td>train/epoch</td><td>1.41123</td></tr><tr><td>train/global_step</td><td>154</td></tr><tr><td>train/grad_norm</td><td>nan</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1454737970954.24</td></tr><tr><td>train_loss</td><td>944635046074.1818</td></tr><tr><td>train_runtime</td><td>23659.1059</td></tr><tr><td>train_samples_per_second</td><td>0.208</td></tr><tr><td>train_steps_per_second</td><td>0.007</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">winter-oath-3</strong> at: <a href='https://wandb.ai/billzhang-25/gemma_storytelling/runs/gcp1v382' target=\"_blank\">https://wandb.ai/billzhang-25/gemma_storytelling/runs/gcp1v382</a><br/> View project at: <a href='https://wandb.ai/billzhang-25/gemma_storytelling' target=\"_blank\">https://wandb.ai/billzhang-25/gemma_storytelling</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_104411-gcp1v382/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def print_training_summary(results):\n",
        "    print(f\"Time: {results.metrics['train_runtime']: .2f}\")\n",
        "    print(f\"Samples/second: {results.metrics['train_samples_per_second']: .2f}\")\n",
        "\n",
        "print_training_summary(results)\n",
        "wandb.finish()\n",
        "\n",
        "# save lora model\n",
        "tuned_lora_model = \"gemma-2b-storytelling-lora\"\n",
        "trainer.model.save_pretrained(tuned_lora_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5e0d9bbf9164f759ac8321e0fe3f6e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "tuned_model = \"gemma-2b\"\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(base_model, tuned_lora_model)\n",
        "model = model.merge_and_unload()\n",
        "# save final tuned model\n",
        "model.save_pretrained(tuned_model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "#model2 = ipex.optimize_transformers(model)  # optimize the model using `ipex`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write a story about a futuristic city where robots and humans coexist, focusing on the friendship between a young girl and her robot companion.\n",
            "Craft a mystery story set in a Victorian-era mansion, involving a secret society and a missing heirloom.\n",
            "Develop a thriller that takes place during a severe snowstorm in a remote mountain cabin, with characters who discover they are not alone.\n",
            "Compose a fantasy tale about a kingdom threatened by a mythical creature, seen through the eyes of a young apprentice wizard tasked with saving the realm.\n",
            "Create a romantic story set on a Mediterranean cruise, where two strangers from different backgrounds fall in love while dealing with personal challenges.\n"
          ]
        }
      ],
      "source": [
        "test_inputs = [\n",
        "\"Write a story about a futuristic city where robots and humans coexist, focusing on the friendship between a young girl and her robot companion.\",\n",
        "\"Craft a mystery story set in a Victorian-era mansion, involving a secret society and a missing heirloom.\",\n",
        "\"Develop a thriller that takes place during a severe snowstorm in a remote mountain cabin, with characters who discover they are not alone.\",\n",
        "\"Compose a fantasy tale about a kingdom threatened by a mythical creature, seen through the eyes of a young apprentice wizard tasked with saving the realm.\",\n",
        "\"Create a romantic story set on a Mediterranean cruise, where two strangers from different backgrounds fall in love while dealing with personal challenges.\"\n",
        "]\n",
        "for text in test_inputs:\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=200, \n",
        "                             do_sample=False, top_k=100,temperature=0.1, \n",
        "                             eos_token_id=tokenizer.eos_token_id)\n",
        "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Maelstrome/gemma-2b-storytelling/commit/dfd430c5f796818d23acaa38a588fb118bc040c7', commit_message='End of training', commit_description='', oid='dfd430c5f796818d23acaa38a588fb118bc040c7', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
